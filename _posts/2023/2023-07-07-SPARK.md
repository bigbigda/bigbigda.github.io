---
layout: post
title: SPARK
categories: SPARK
description:
keywords: BigData
---



### SPARK存储机制

#### 堆内存储

spark的内核由scala语言完成，其运行在JVM上，所以spark在运行时具有堆（heap）的概念。进一步，其将堆分为四部分

| **Storage Memory**   | 存储cached数据              |
| -------------------- | --------------------------- |
| **Execution Memory** | 用于存储shuffle操作时的数据 |
| **User Memory**      | 存储用户代码中的数据结构    |
| **Reserved Memory**  | 用于spark自身               |

![image-20230707113552275](http://pic.inoodles.online/imgimage-20230707113552275.png)

- 在spark 1.6以前，spark为[StaticMemoryManager](https://github.com/apache/spark/blob/branch-1.6/core/src/main/scala/org/apache/spark/memory/StaticMemoryManager.scala)，在此之后为 [UnifiedMemoryManager](https://github.com/apache/spark/blob/branch-1.6/core/src/main/scala/org/apache/spark/memory/UnifiedMemoryManager.scala)。在静态存储管理时，spark.storage.memoryFraction和spark.shuffle.memoryFraction分别用于控制storage memory和shuffle memory的比例，在此之后此参数失效（除非配置spark.memory.useLegacyMode）
- 在统一存储管理中，使用spark.memory.fraction控制storage和shuffle存储的总比例

#### 堆外存储

SPARK的堆外内存可分为两种

- 一种是用于JVM本身、字符串等开销
- 另一种是用于spark程序本身，存放数据等

![image-20230707114948882](http://pic.inoodles.online/imgimage-20230707114948882.png)

与之相关的主要有两组参数，一组是spark.yarn.executor.memoryOverhead，另一组是spark.memory.offHeap.enabled和spark.memory.offHeap.size，对于spark1.x和2.x，spark.yarn.executor.memoryOverhead控制整个堆外存储的大小，第二种堆外存储通过spark.memory.offHeap.enabled和spark.memory.offHeap.size显式配置；对于spark3.x，这两组参数独立控制两种堆外存储大小。此外，第一种堆外存储默认开启，大小为excutor的10%，且最小为384MB。



### SPARK

- executor-cores 表示一个executor的核数，也是一个executor最大并行的task数

- spark.dynamicAllocation.maxExecutors 最大使用饿的executor数目

  

