---
layout: post
title: Spark语法
categories: snip
description:
keywords: SQL,Spark,Pyspark,Scala,,Snip
---

**如无特殊说明则为PySpark语法**

#### 配置环境

```python
%%spark
--conf spark.yarn.queue=root.zw01.hadoop-mining.ad-online
ffsfsdconf spark.driver.maxResultSize=16g
```



#### 读hdfs

```python
offline_data = sc.textFile("viewfs://hadoop-meituan/user/hadoop-mining/user/guopeng16/dpxg/search/offline_data_f/2022-12-07")
```

#### 处理
```python
def f1(line):
    line_s = line.split('\t')
    req = line_s[3]
    shopid = line_s[1]
    xgid = line_s[7]
    expid = line_s[16]
    feature = line_s[15]
    return (req, shopid, xgid, expid, feature) 
offline_data.map(lambda line :f1(line) ).take(3)
```
#### 过滤
```python
def f1(line):
    line_s = line.split('\t')
    shopid = line_s[1]
    reqid = line_s[3]
    if shopid == '745349529' and reqid == '33ef1918-dea1-4c0f-920b-55d414b10098':
        return True
    elif shopid == '1540560422' and reqid == '1511426d-e734-4a3b-9b80-d3bb4bb1c33c':
        return True
    else:
        return False
offline_data.filter( lambda line : f1(line)).take(10)
```



#### 过滤（lambda表达式）

```python
rdd1.filter(lambda line:len(line.split('\t'))!=32).count()
```

#### rdd2hive

```python
from pyspark.sql.types import StringType
from pyspark.sql.types import StructField
from pyspark.sql.types import StructType
SCHEMA = StructType([
    StructField('req', StringType()),
    StructField('shopid', StringType()),
    StructField('xgid', StringType()),
    StructField('expid', StringType()),
 StructField('feature', StringType())
])

offline_data.filter(lambda line : len(line.split('\t'))> 20).map(lambda line :f1(line) ).toDF(SCHEMA).createOrReplaceTempView("temp_view_name")
```

```python
%%sql mydf --preview --quiet

create table tmp.tmp_guop_v1213 as 
select * from temp_view_name
where expid = '21-1404:7459'
```

```sql
select  approx_percentile(querytagnumber,array[0,0.3,0.5,0.7, 1]) from xxx
```



### 基于文本创建hive表(scala-spark)

```scala
val myDF = sc.parallelize(Seq(
    ("A", "John", 1, 3),
    ("A", "Bob", 2, 5),
    ("A", "Sam", 3, 1),
    ("B", "Kim", 1, 4),
    ("B", "John", 2, 3),
    ("B", "Ria", 3, 5))).toDF("ID", "NAME", "SEQ", "NUMBER")
myDf.createOrReplaceTempView("mytempTable") 
sqlContext.sql("create table mytable as select * from mytempTable");
```