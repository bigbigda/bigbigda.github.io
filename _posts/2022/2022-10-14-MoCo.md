---
layout: post
title: MoCo
categories: Contrastive Learning
description:
keywords: CV,Contrastive Learning
---

## Momentum Contrast for Unsupervised Visual Representation Learning

### 简介

cvpr2020 Best Paper提名 He Kaiming

在文本领域，bert等自监督学习（**Self-Supervised Learning**）已经得到了广泛应用，但其在CV领域的进展一直比较缓慢，之前也有不少基于对比学习的尝试，本文将他们都归类为基于构建动态词典的方式。具体而言，无监督学习被看做训练一个encoder进行词典查找，使得正样本更加接近，负样本具体更远。但作者认为之前工作没有同时处理好（1）字典比较大；(2)字典训练过程中保持一致。

本文引入了一种Momentum的encoder更新策略来解决上述问题。本文最终实验结果在分类、检测、分割等任务上均展示出了和监督学习可比甚至更好的效果，证明了监督学习的可行性。



### 关键点

- 无监督学习研究主要包括两方面：代理任务和Loss函数。本文主要聚焦于Loss函数
- 文中对比了三种架构：end2end、memory bank和MoCo
  - end2end的方法，随着batchsize的增大效果会越来越好，但是受限于batchsize，实际无法变的很大

### 架构图

![image-20221018110959714](http://pic.inoodles.online/imgimage-20221018110959714.png)



### 伪代码（来自论文）

```
f_k.params = f_q.params # 初始化
for x in loader: # 输入一个图像序列x，包含N张图，没有标签
    x_q = aug(x) # 用于查询的图（数据增强得到）
    x_k = aug(x) # 模板图（数据增强得到），自监督就体现在这里，只有图x和x的数据增强才被归为一类
    q = f_q.forward(x_q) # 提取查询特征，输出NxC
    k = f_k.forward(x_k) # 提取模板特征，输出NxC
    # 不使用梯度更新f_k的参数，这是因为文章假设用于提取模板的表示应该是稳定的，不应立即更新
    k = k.detach() 
    # 这里bmm是分批矩阵乘法
    l_pos = bmm(q.view(N,1,C), k.view(N,C,1)) # 输出Nx1，也就是自己与自己的增强图的特征的匹配度
    l_neg = mm(q.view(N,C), queue.view(C,K)) # 输出Nxk，自己与上一批次所有图的匹配度（全不匹配）
    logits = cat([l_pos, l_neg], dim=1) # 输出Nx(1+k)
    labels = zeros(N)
    # NCE损失函数，就是为了保证自己与自己衍生的匹配度输出越大越好，否则越小越好
    loss = CrossEntropyLoss(logits/t, labels) 
    loss.backward()
    update(f_q.params) # f_q使用梯度立即更新
    # 由于假设模板特征的表示方法是稳定的，因此它更新得更慢，这里使用动量法更新，相当于做了个滤波。
    f_k.params = m*f_k.params+(1-m)*f_q.params 
    enqueue(queue, k) # 为了生成反例，所以引入了队列
    dequeue(queue)
```



### 参考资料

https://zhuanlan.zhihu.com/p/382763210 （讲得非常详细清楚）
