---
layout: post
title: MAE
categories: Transformer
description:
keywords: CV,transformer,Autoencoders

---

## Masked Autoencoders Are Scalable Vision Learners

CVPR 2021  

He Kaiming

### 简介

本文的最大意义在于在图像领域引入masked autoencoders训练任务，实现了自监督学习。

MAE可以看做CV版的bert

Transformer->BERT->VIT->MAE



### 架构

![image-20221014135446680](http://pic.inoodles.online/imgimage-20221014135446680.png)



### 相关工作

MAE之前，BEiT也在尝试类似思路，但是BEiT还没有激进的直接去学习pixel粒度信息

#### MAE的细节

- 非对称的encoder和decoder：在encoder部分，不对masked patch进行编码，在decoder前重新插入这些patches
- 轻量化的decoder：相比encoder，decoder的层数更少



#### MAE的实验

- 作者对mask的方法（随机、网格状、大块）、decoder层数、是否encoder mask、decoder target是否正则等进行了大量实验
- 一个有意思的现象是，作者发现VIT原始论文中VIT-H在ImageNet上训练的效果被低估了（VIT-L由于模型过大，容易过拟合），通过调整训练参数，准确度可以从76.5提升到82.5（huge improve），再次说明**训练方法的重要性**，至少对CV领域
- 还分析了fine-tune和linear probing的效果，首先fine-tune效果肯定要好的多；对比MoCo v3，作者发现MAE linear probing效果要差一些，但是fine-tune或partial fine-tune下效果则明显变化，作者认为这说明MAE学到的特征非线性更强

### 参考资料

https://www.zhihu.com/question/498364155

