<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.3">Jekyll</generator><link href="https://bigbigda.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://bigbigda.github.io/" rel="alternate" type="text/html" /><updated>2023-11-22T18:12:04+08:00</updated><id>https://bigbigda.github.io/feed.xml</id><title type="html">个人博客</title><subtitle></subtitle><author><name>nice</name></author><entry><title type="html"></title><link href="https://bigbigda.github.io/2023/11/22/2023-11-21-Git/" rel="alternate" type="text/html" title="" /><published>2023-11-22T18:12:04+08:00</published><updated>2023-11-22T18:12:04+08:00</updated><id>https://bigbigda.github.io/2023/11/22/2023-11-21-Git</id><content type="html" xml:base="https://bigbigda.github.io/2023/11/22/2023-11-21-Git/">&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h2 id=&quot;tips&quot;&gt;Tips&lt;/h2&gt;

&lt;h3 id=&quot;origin-和-master-区别&quot;&gt;origin 和 master 区别&lt;/h3&gt;

&lt;p&gt;origin为远端/仓库名字，可以在git目录中输入 git remote -v 查看当前本地仓库的remote&lt;/p&gt;

&lt;p&gt;master为默认分支名称&lt;/p&gt;

&lt;h2 id=&quot;code&quot;&gt;Code&lt;/h2&gt;

&lt;h3 id=&quot;参考资料&quot;&gt;参考资料&lt;/h3&gt;
&lt;p&gt;https://km.sankuai.com/page/28097486
https://www.liaoxuefeng.com/wiki/896043488029600/897889638509536&lt;/p&gt;
&lt;h3 id=&quot;推送&quot;&gt;推送&lt;/h3&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git push

# 对新建远程仓库的第一次推送，需要指定主分支名master
git push &amp;lt;远程主机名&amp;gt; &amp;lt;本地分支名&amp;gt;:&amp;lt;远程分支名&amp;gt;
git push origin master:master
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;文件操作&quot;&gt;文件操作&lt;/h3&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# 检出最后一次提交的文件覆盖当前文件，或者说放弃当前文件的修改
git checkout file 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;创建新分支&quot;&gt;创建新分支&lt;/h3&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# 方法1，直接从当前分支创建hotfix分支
git branch hotfix 

# 方法2，从当前分支创建hotfix分支，并切换到hotfix分支
git checkout -b hotfix 

# 方法3，从master分支创建hotfix分支，并切换到hotfix分支
git checkout -b hotfix master 

git checkout -b v0.9rc1 origin/v0.9rc1

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;清理远程分支记录&quot;&gt;清理远程分支记录&lt;/h3&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git push origin --delete  分支名
git remote prune origin
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;设置push到远程的默认分支&quot;&gt;设置push到远程的默认分支&lt;/h3&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; git push --set-upstream origin 分支名
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;### 设置push的默认方式&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  git config --global push.default simple
  仅push当前分支到同名分支
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>nice</name></author></entry><entry><title type="html"></title><link href="https://bigbigda.github.io/2023/11/22/2023-11-21-Python/" rel="alternate" type="text/html" title="" /><published>2023-11-22T18:12:04+08:00</published><updated>2023-11-22T18:12:04+08:00</updated><id>https://bigbigda.github.io/2023/11/22/2023-11-21-Python</id><content type="html" xml:base="https://bigbigda.github.io/2023/11/22/2023-11-21-Python/">&lt;p&gt;[toc]&lt;/p&gt;

&lt;h3 id=&quot;路径下文件列表&quot;&gt;路径下文件列表&lt;/h3&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import os
files=os.listdir()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;正则表达式过滤列表&quot;&gt;正则表达式过滤列表&lt;/h3&gt;

&lt;p&gt;search表示存在即匹配上，match需要完全匹配&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import re
files = [ &apos;a&apos;,&apos;b&apos;,&apos;c&apos; ]
regex = re.compile(r&apos;&apos;)
selected_files = list(filter(regex.search, files))
# selected_files = list(filter(regex.match, files))

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h3 id=&quot;文件操作&quot;&gt;文件操作&lt;/h3&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import shutil
shutil.move( src, dst)        # 移动文件或重命名
shutil.copy( src, dst)        # 复制文件
os.remove(path)              # 删除文件
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>nice</name></author></entry><entry><title type="html"></title><link href="https://bigbigda.github.io/2023/11/22/2023-11-21-Shell/" rel="alternate" type="text/html" title="" /><published>2023-11-22T18:12:04+08:00</published><updated>2023-11-22T18:12:04+08:00</updated><id>https://bigbigda.github.io/2023/11/22/2023-11-21-Shell</id><content type="html" xml:base="https://bigbigda.github.io/2023/11/22/2023-11-21-Shell/">&lt;p&gt;[TOC]&lt;/p&gt;

&lt;h4 id=&quot;shell命令解释网站&quot;&gt;shell命令解释网站&lt;/h4&gt;
&lt;p&gt;https://explainshell.com/&lt;/p&gt;

&lt;h4 id=&quot;history&quot;&gt;history&lt;/h4&gt;
&lt;p&gt;history + 数字 ：显示最近若干条命令&lt;/p&gt;
&lt;h4 id=&quot;sort&quot;&gt;sort&lt;/h4&gt;
&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;-t&lt;/span&gt; 表示分隔符 &lt;span class=&quot;nt&quot;&gt;-k&lt;/span&gt; 表示第几列 &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; 按数字大小排序
&lt;span class=&quot;nb&quot;&gt;sort&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-k&lt;/span&gt; 1 &lt;span class=&quot;nt&quot;&gt;-t&lt;/span&gt; 刂 filename

文件去重
&lt;span class=&quot;nb&quot;&gt;sort&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; test.txt | &lt;span class=&quot;nb&quot;&gt;uniq&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; tmp
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h4 id=&quot;cut&quot;&gt;cut&lt;/h4&gt;
&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;选取文件第二三列 &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt;可以指定分隔符，默认空格
&lt;span class=&quot;nb&quot;&gt;cut&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-f2&lt;/span&gt;,3 filename 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h4 id=&quot;tr替换文件中字符&quot;&gt;tr替换文件中字符&lt;/h4&gt;
&lt;p&gt;参考 https://www.jianshu.com/p/779f40985b20&lt;/p&gt;
&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;tr&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-s&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;|&quot;&lt;/span&gt; &amp;lt; file 将文件中换行号替换为”|&lt;span class=&quot;s2&quot;&gt;&quot;，实现合并多行为一行

&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;sed&quot;&gt;sed&lt;/h4&gt;
&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;储备1: 将第2个冒号替换
&lt;span class=&quot;nb&quot;&gt;sed&lt;/span&gt; “s/:/刂/2”

储备2: 将满足条件行的第二个冒号替换
&lt;span class=&quot;nb&quot;&gt;sed&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;/\(.*:.*\):\(.*:.*:.*:.*:\)/\1刂\2/&apos;&lt;/span&gt;      filename
&lt;span class=&quot;nb&quot;&gt;sed&lt;/span&gt;  &lt;span class=&quot;s1&quot;&gt;&apos;s/\(.*:.*\):\(.*:.*:.*:.*:\)/\1刂\2/;n&apos;&lt;/span&gt;  filename

储备3：删除偶数行
&lt;span class=&quot;nb&quot;&gt;sed&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;n;d” filename

储备4:利用逗号匹配多行, BEGIN/END可以是数字，也可以是用于匹配的字符串
 sed -n -e ’/BEGIN/,/END/p’ filename

储备5：删除上2行，下9行，中间{clipboard}为查找的文本
sed -i &apos;:a;N;s/&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;/&amp;amp;/2;Ta;/{clipboard}/!{P;D};:b;N;s/&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;/&amp;amp;/11;Tb;d&apos; part-00000
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# 处理推荐语流程
step1: 将所有奇数行冒号替换为刂
sed &apos;s/:/刂/g;n&apos; rec-noquery-20200116.txt &amp;gt; rec-noquery-20200116.txt-step1

step1.1: 显示所有具有超过5个刂的行
grep -n &quot;.*刂.*刂.*刂.*刂.*刂.*&quot; rec-noquery-20200114.txt-step1

 
step2: 删除所有具有超过4个刂的行
sed  &apos;/.*刂.*刂.*刂.*刂.*刂.*/,+1d&apos; rec-noquery-20200116.txt-step1 &amp;gt; rec-noquery-20200116.txt-step2

step3: 
sed -n &apos;p;n&apos; rec-noquery-20200116.txt-step2 &amp;gt; rec-noquery-20200116.txt-step3
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#no_query
sed   &apos;/^[^{].*:.*/,+1d&apos;  output.txt &amp;gt; output.txt-step1
sed -n &apos;p;n&apos;  output.txt-step1 &amp;gt; output.txt-step2
python process_file.py  output.txt-step2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;grep&quot;&gt;grep&lt;/h4&gt;
&lt;p&gt;grep 按行模式工作，默认情况下不能跨行，可以采用pcregrep&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# 统计文件中含有某个字符串的行数&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;grep&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; objStr  filename|wc &lt;span class=&quot;nt&quot;&gt;-l&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;grep&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; 规则文件  被查找文件 （规则文件中每一行为一个关键词）

&lt;span class=&quot;c&quot;&gt;# grep 查看上下几行&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;grep&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-C&lt;/span&gt; 5 &lt;span class=&quot;nt&quot;&gt;-rn&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;materialId=210&quot;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;-A&lt;/span&gt; 后几行
&lt;span class=&quot;nt&quot;&gt;-B&lt;/span&gt; 前几行
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;set&quot;&gt;set&lt;/h4&gt;
&lt;p&gt;参考 https://coderwall.com/p/fkfaqq/safer-bash-scripts-with-set-euxo-pipefail&lt;/p&gt;
&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; errexit 表示当之后命令行中任意一个返回非0值，则shell立即退出
&lt;span class=&quot;nb&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; pipefail：正常情况下一个管道命令的返回值由管道最右侧命令的返回值决定，set &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; pipefail使得如果管道中任意一处返回非0，则该管道返回非0
&lt;span class=&quot;nb&quot;&gt;set&lt;/span&gt; +x 表示停止某个功能
&lt;span class=&quot;nb&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-u&lt;/span&gt; 使得使用任何未设置的变量返回error
&lt;span class=&quot;nb&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-x&lt;/span&gt; 在执行任何一条command之前先打印
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>nice</name></author></entry><entry><title type="html">SQL语法</title><link href="https://bigbigda.github.io/2023/11/21/SQL/" rel="alternate" type="text/html" title="SQL语法" /><published>2023-11-21T00:00:00+08:00</published><updated>2023-11-21T00:00:00+08:00</updated><id>https://bigbigda.github.io/2023/11/21/SQL</id><content type="html" xml:base="https://bigbigda.github.io/2023/11/21/SQL/">&lt;p&gt;[TOC]&lt;/p&gt;

&lt;h3 id=&quot;正则表达式&quot;&gt;正则表达式&lt;/h3&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- regex_extract 第二个参数为正则表达式，第三个参数表示位置，为0时返回参数二正则表达式匹配到的字符串，为其他正整数时为该正则表达式第N个括号内的内容，如果未匹配成功，返回空字符串（与第三个参数取值无关）&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ab_trace_tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;regexp_extract&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ab_trace_tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;.*(22-86:)&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;regexp_extract&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ab_trace_tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;.*(22-86:)&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;regexp_extract&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ab_trace_tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;(22-108:).*(?=,)&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;-- 贪婪匹配       &lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;regexp_extract&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ab_trace_tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;(22-108:).*?(?=,)&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;-- 非贪婪匹配&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hive_table_name&lt;/span&gt;
 &lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;20200115&apos;&lt;/span&gt;
   &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;slot_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10002&lt;/span&gt;
 &lt;span class=&quot;k&quot;&gt;limit&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;其他例子&lt;/p&gt;
&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;regexp_extract&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ab_trace_tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;(21-109:)(&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\d&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;{3}$|.*?(?=,))&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pattern&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;(?&amp;lt;=delocText&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;)(.*?)(?=&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;)&quot;&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h4 id=&quot;hive&quot;&gt;Hive&lt;/h4&gt;
&lt;p&gt;Hive中使用正则表达式的三种方式&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;rlike  用于where语句中进行筛选&lt;/li&gt;
  &lt;li&gt;regexp_extract  用于提取匹配的字符串&lt;/li&gt;
  &lt;li&gt;regexp_replace  用于替换
    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;-- hive
select slot_id, request_id, source, content, id from db.hive_table_name
       WHERE dt=&apos;20200117&apos; and id rlike &apos;test.*&apos;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;h4 id=&quot;presto&quot;&gt;Presto&lt;/h4&gt;
  &lt;/li&gt;
  &lt;li&gt;regexp_extract
    &lt;ul&gt;
      &lt;li&gt;支持regexp_extract(string, pattern), 相比之下，hive不支持此语法，如果没有第三个参数，hive默认添加参数1，如果没有分组，则报错&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;regexp_extract_all
    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;select slot_id, request_id, source, content, id from db.hive_table_name
       WHERE dt=&apos;20200117&apos; and regexp_like(id,&apos;test&apos;)    
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;json处理及字符串拆分&quot;&gt;json处理及字符串拆分&lt;/h3&gt;

&lt;h4 id=&quot;presto-1&quot;&gt;presto&lt;/h4&gt;
&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;table&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expanded_recall_0115&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;request_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;shop_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;launch_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;json_extract&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;CAST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extensions&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;$.xgs.defineTalkSwitch&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;defineTalk&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;json_extract&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;CAST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extensions&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;$.xgs.smartTalkSwitch&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;samrtTalk&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;json_extract&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;CAST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extensions&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;$.xgs.xgsMaterial.source&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;json_extract&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;CAST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extensions&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;$.xgs.xgsMaterial.id&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;json_extract&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;CAST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extensions&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;$.xgs.xgsMaterial.content&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;content&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;request_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
               &lt;span class=&quot;n&quot;&gt;json_extract&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;concat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;{&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;regexp_replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tmp_col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\[\{&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;}&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;$.dp_shop_id&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shop_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
               &lt;span class=&quot;n&quot;&gt;json_extract&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;concat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;{&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;regexp_replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tmp_col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\[\{&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;}&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;$.launch_id&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;launch_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
               &lt;span class=&quot;n&quot;&gt;json_extract&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;concat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;{&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;regexp_replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tmp_col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\[\{&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;}&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;$.image_urls&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
               &lt;span class=&quot;n&quot;&gt;json_extract&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;concat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;{&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;regexp_replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tmp_col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\[\{&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;}&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;$.extensions&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;extensions&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hive_table_name&lt;/span&gt;
         &lt;span class=&quot;k&quot;&gt;CROSS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;UNNEST&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;},{&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tb&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tmp_col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
         &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;20200112&apos;&lt;/span&gt;
           &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;slot_id&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10002&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
       &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;-- 同时存在array和json解析&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;json_extract&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;json_array_get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;json_extract&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;$.richtextlist&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;$.text&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h4 id=&quot;hive-1&quot;&gt;hive&lt;/h4&gt;
&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;request_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;shop_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;launch_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;get_json_object&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extensions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;$.zgs.defineTalkSwitch&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;defineTalkSwitch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;get_json_object&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extensions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;$.zgs.smartTalkSwitch&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;smartTalkSwitch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;get_json_object&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extensions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;$.zgs.zgsMaterial.source&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;get_json_object&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extensions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;$.zgs.zgsMaterial.id&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;get_json_object&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extensions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;$.zgs.zgsMaterial.content&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;content&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;dt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;hour&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;request_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
               &lt;span class=&quot;n&quot;&gt;tmp_col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
               &lt;span class=&quot;n&quot;&gt;get_json_object&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;concat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;{&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;regexp_replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tmp_col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\\&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\\&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;{&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;}&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;$.dp_shop_id&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shop_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
               &lt;span class=&quot;n&quot;&gt;get_json_object&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;concat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;{&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;regexp_replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tmp_col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\\&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\\&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;{&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;}&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;$.launch_id&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;launch_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
               &lt;span class=&quot;n&quot;&gt;get_json_object&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;concat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;{&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;regexp_replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tmp_col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\\&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\\&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;{&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;}&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;$.image_urls&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
               &lt;span class=&quot;n&quot;&gt;get_json_object&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;concat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;{&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;regexp_replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tmp_col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\\&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\\&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;{&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;}&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;$.extensions&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;extensions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
               &lt;span class=&quot;n&quot;&gt;dt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
               &lt;span class=&quot;n&quot;&gt;hour&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hive_table_name&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;lateral&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;view&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;explode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\\&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\\&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;{&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tb&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tmp_col&lt;/span&gt;
         &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;$now.datekey&apos;&lt;/span&gt;
           &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;slot_id&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10002&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10011&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
       &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;c&lt;/span&gt;
     
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;时间转换&quot;&gt;时间转换&lt;/h3&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- Hive&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;unix_timestamp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;20190909&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;yyyyMMdd&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hive_table_name&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;from_unixtime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unix_timestamp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;20190909&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;yyyyMMdd&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;yyyy-MM-dd&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;from_unixtime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unix_timestamp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hp_stat_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;yyyy-mm-dd&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;yyyymmdd&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;date_format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;date_parse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;20190805&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;%Y%m%d&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;%Y-%m-%d&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;datediff&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;2020-05-14&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;date_format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;cast&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;2020-05-01 11:48:15&apos;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;timestamp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;yyyy-MM-dd&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;-- Presto&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;format_datetime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;date_parse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;2020-03-02&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;%Y-%m-%d&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;yyyyMMdd&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;datediff&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;2020-05-14&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format_datetime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;cast&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;createtime&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;timestamp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;yyyy-MM-dd&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;date_format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;date_parse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;20200302&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;%Y%m%d&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;interval&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;-1&apos;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;day&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;%Y%m%d&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;字符串分割拼接&quot;&gt;字符串分割&amp;amp;拼接&lt;/h3&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- Hive&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mt_poi_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;dp_shop_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;mt_poi_first_cate_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;tag&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hive_table_name&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;lateral&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;view&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;explode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tags&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;刂&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;myTable&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tag&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;-- Presto&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;student&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;score&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tests&lt;/span&gt;
 &lt;span class=&quot;k&quot;&gt;CROSS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;UNNEST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
 
&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mt_poi_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;dp_shop_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;mt_poi_first_cate_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;array_join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array_agg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tags&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;刂&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hive_table_name&lt;/span&gt;
 &lt;span class=&quot;k&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mt_poi_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;dp_shop_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;mt_poi_first_cate_id&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;snippets&quot;&gt;snippets&lt;/h3&gt;

&lt;h4 id=&quot;case语句&quot;&gt;case语句&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&quot;language-SQL&quot;&gt;SELECT CASE WHEN (exp like &apos;%2-194:1420%&apos;) THEN &apos;lr_color1&apos;
            WHEN (exp like &apos;%2-194:1701%&apos;) THEN &apos;lr_color2&apos;
            WHEN (exp like &apos;%2-226:2139%&apos;) THEN &apos;food_color1&apos;
            WHEN (exp like &apos;%2-256:2140%&apos;) THEN &apos;xiuyu_color1&apos;
            WHEN (exp like &apos;%2-271:2141%&apos;) THEN &apos;yiliao_color1&apos;
            ELSE &apos;others&apos;
             END as expid
  FROM db.hive_table_name
 where dt = &apos;20210316&apos;
   and id is not null
   and id != &apos;&apos;
   and pos = 1

&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&quot;时间&quot;&gt;时间&lt;/h4&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&apos;${now.datekey}&apos;
&apos;${now.date}&apos;
&apos;${now.delta(days=365).date}&apos;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;百分比&quot;&gt;百分比&lt;/h4&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;approx_percentile(dealidcnt,array[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.99,1])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;转义字符&quot;&gt;转义字符&lt;/h4&gt;

&lt;p&gt;prosto中转义字符用\,  hive中转义字符需要用\\&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- presto&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shopid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mark_number_feature&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mark_number&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shopid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;regexp_extract&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;(wish&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\^&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;).*?(?=&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\^&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;)&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mark_number_feature&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;regexp_extract&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;(?&amp;lt;=wish&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\^&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;).*?(?=&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\^&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;)&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mark_number&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;row_number&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;over&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;partition&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shopid&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;order&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partition_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reqid&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;desc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rn&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hive_table_name&lt;/span&gt;
 &lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partition_date&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;2020-04-01&apos;&lt;/span&gt;
   &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;slot_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10010&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;-- hive&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shopid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;regexp_extract&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;(wish&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\\&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;^).*?(?=&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\\&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;^)&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mark_number_feature&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;regexp_extract&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;(?&amp;lt;=wish&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\\&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;^).*?(?=&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\\&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;^)&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mark_number&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;row_number&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;over&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;partition&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shopid&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;order&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partition_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reqid&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;desc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rn&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hive_table_name&lt;/span&gt;
 &lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partition_date&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;2020-04-01&apos;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;slot_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10010&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;参考资料&quot;&gt;参考资料&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;presto和hive解析json
    &lt;ul&gt;
      &lt;li&gt;https://www.cnblogs.com/drjava/p/10536922.html&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>nice</name></author><category term="snip" /><summary type="html">[TOC]</summary></entry><entry><title type="html">Spark机制</title><link href="https://bigbigda.github.io/2023/07/07/Spark-Basic/" rel="alternate" type="text/html" title="Spark机制" /><published>2023-07-07T00:00:00+08:00</published><updated>2023-07-07T00:00:00+08:00</updated><id>https://bigbigda.github.io/2023/07/07/Spark-Basic</id><content type="html" xml:base="https://bigbigda.github.io/2023/07/07/Spark-Basic/">&lt;h3 id=&quot;spark存储机制&quot;&gt;Spark存储机制&lt;/h3&gt;

&lt;h4 id=&quot;堆内存储&quot;&gt;堆内存储&lt;/h4&gt;

&lt;p&gt;spark的内核由scala语言完成，其运行在JVM上，所以spark在运行时具有堆（heap）的概念。进一步，其将堆分为四部分&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;strong&gt;Storage Memory&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;存储cached数据&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Execution Memory&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;用于存储shuffle操作时的数据&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;User Memory&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;存储用户代码中的数据结构&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Reserved Memory&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;用于spark自身&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;img src=&quot;http://pic.inoodles.online/imgimage-20230707113552275.png&quot; alt=&quot;image-20230707113552275&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;在spark 1.6以前，spark为&lt;a href=&quot;https://github.com/apache/spark/blob/branch-1.6/core/src/main/scala/org/apache/spark/memory/StaticMemoryManager.scala&quot;&gt;StaticMemoryManager&lt;/a&gt;，在此之后为 &lt;a href=&quot;https://github.com/apache/spark/blob/branch-1.6/core/src/main/scala/org/apache/spark/memory/UnifiedMemoryManager.scala&quot;&gt;UnifiedMemoryManager&lt;/a&gt;。在静态存储管理时，spark.storage.memoryFraction和spark.shuffle.memoryFraction分别用于控制storage memory和shuffle memory的比例，在此之后此参数失效（除非配置spark.memory.useLegacyMode）&lt;/li&gt;
  &lt;li&gt;在统一存储管理中，使用spark.memory.fraction控制storage和shuffle存储的总比例&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;堆外存储&quot;&gt;堆外存储&lt;/h4&gt;

&lt;p&gt;SPARK的堆外内存可分为两种&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;一种是用于JVM本身、字符串等开销&lt;/li&gt;
  &lt;li&gt;另一种是用于spark程序本身，存放数据等&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;http://pic.inoodles.online/imgimage-20230707114948882.png&quot; alt=&quot;image-20230707114948882&quot; /&gt;&lt;/p&gt;

&lt;p&gt;与之相关的主要有两组参数，一组是spark.yarn.executor.memoryOverhead，另一组是spark.memory.offHeap.enabled和spark.memory.offHeap.size，对于spark1.x和2.x，spark.yarn.executor.memoryOverhead控制整个堆外存储的大小，第二种堆外存储通过spark.memory.offHeap.enabled和spark.memory.offHeap.size显式配置；对于spark3.x，这两组参数独立控制两种堆外存储大小。此外，第一种堆外存储默认开启，大小为excutor的10%，且最小为384MB。&lt;/p&gt;

&lt;h3 id=&quot;spark&quot;&gt;SPARK&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;executor-cores 表示一个executor的核数，也是一个executor最大并行的task数&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;spark.dynamicAllocation.maxExecutors 最大使用饿的executor数目&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;spark调优&quot;&gt;spark调优&lt;/h2&gt;

&lt;h3 id=&quot;代码优化&quot;&gt;代码优化&lt;/h3&gt;
&lt;h4 id=&quot;避免创建重复rdd&quot;&gt;避免创建重复RDD&lt;/h4&gt;

&lt;h4 id=&quot;尽可能复用同一个rdd&quot;&gt;尽可能复用同一个rdd&lt;/h4&gt;

&lt;h4 id=&quot;对多次使用的rdd进行持久化&quot;&gt;对多次使用的rdd进行持久化&lt;/h4&gt;

&lt;p&gt;sc.textFile(“hdfs://192.168.0.1:9000/hello.txt”).cache()&lt;/p&gt;

&lt;p&gt;sc.textFile(“hdfs://192.168.0.1:9000/hello.txt”).persist(StorageLevel.MEMORY_AND_DISK_SER)&lt;/p&gt;

&lt;h4 id=&quot;尽量避免使用shuffle类算子&quot;&gt;尽量避免使用shuffle类算子&lt;/h4&gt;
&lt;p&gt;例如reduceByKey、join、reparation等算子&lt;/p&gt;

&lt;h4 id=&quot;使用map-side预聚合的shuffle操作&quot;&gt;使用map-side预聚合的shuffle操作&lt;/h4&gt;
&lt;p&gt;如果一定要使用shuffle操作，尽量可以使用map-side预聚合的算子（所谓map-side，是指每个节点本地对相同的key进行一次聚合操作，预聚合后，每个节点本地就只会有一条相同的key）
建议使用reduceByKey或aggregateByKey替代groupByKey&lt;/p&gt;

&lt;h3 id=&quot;配置优化&quot;&gt;配置优化&lt;/h3&gt;
&lt;h4 id=&quot;num-executors&quot;&gt;num-executors&lt;/h4&gt;
&lt;p&gt;该参数用于设置Spark作业总共要用多少个Executor进程来执行。如果不设置的话，默认只会给你启动少量的Executor进程，此时你的Spark作业的运行速度是非常慢&lt;/p&gt;

&lt;p&gt;每个Spark作业的运行一般设置50~100个左右的Executor进程比较合适，设置太少或太多的Executor进程都不好。设置的太少，无法充分利用集群资源；设置的太多的话，大部分队列可能无法给予充分的资源。&lt;/p&gt;

&lt;h4 id=&quot;executor-memory&quot;&gt;executor-memory&lt;/h4&gt;
&lt;p&gt;该参数用于设置每个Executor进程的内存。Executor内存的大小，很多时候直接决定了Spark作业的性能，而且跟常见的JVM OOM异常，也有直接的关联。&lt;/p&gt;

&lt;p&gt;每个Executor进程的内存设置4G~8G较为合适。但是这只是一个参考值，具体的设置还是得根据不同部门的资源队列来定。可以看看自己团队的资源队列的最大内存限制是多少，num-executors乘以executor-memory，是不能超过队列的最大内存量的。此外，如果你是跟团队里其他人共享这个资源队列，那么申请的内存量最好不要超过资源队列最大总内存的1/3~1/2，避免你自己的Spark作业占用了队列所有的资源，导致别的同学的作业无法运行。&lt;/p&gt;

&lt;h4 id=&quot;executor-cores&quot;&gt;executor-cores&lt;/h4&gt;
&lt;p&gt;该参数用于设置每个Executor进程的CPU core数量。这个参数决定了每个Executor进程并行执行task线程的能力。因为每个CPU core同一时间只能执行一个task线程，因此每个Executor进程的CPU core数量越多，越能够快速地执行完分配给自己的所有task线程。&lt;/p&gt;

&lt;p&gt;Executor的CPU core数量设置为2~4个较为合适。同样得根据不同部门的资源队列来定，可以看看自己的资源队列的最大CPU core限制是多少，再依据设置的Executor数量，来决定每个Executor进程可以分配到几个CPU core。同样建议，如果是跟他人共享这个队列，那么num-executors * executor-cores不要超过队列总CPU core的1/3~1/2左右比较合适，也是避免影响其他同学的作业运行。&lt;/p&gt;

&lt;h4 id=&quot;driver-memory&quot;&gt;driver-memory&lt;/h4&gt;
&lt;p&gt;该参数用于设置Driver进程的内存。&lt;/p&gt;

&lt;p&gt;Driver的内存通常来说不设置，或者设置1G左右应该就够了。唯一需要注意的一点是，如果需要使用collect算子将RDD的数据全部拉取到Driver上进行处理，那么必须确保Driver的内存足够大，否则会出现OOM内存溢出的问题。&lt;/p&gt;

&lt;h4 id=&quot;sparkdefaultparallelism&quot;&gt;spark.default.parallelism&lt;/h4&gt;
&lt;p&gt;该参数用于设置每个stage的默认task数量。这个参数极为重要，如果不设置可能会直接影响你的Spark作业性能。&lt;/p&gt;

&lt;p&gt;Spark作业的默认task数量为500~1000个较为合适。Spark官网建议的设置原则是，设置该参数为num-executors * executor-cores的2~3倍较为合适。&lt;/p&gt;

&lt;h4 id=&quot;sparkstoragememoryfraction&quot;&gt;spark.storage.memoryFraction&lt;/h4&gt;
&lt;p&gt;该参数用于设置RDD持久化数据在Executor内存中能占的比例，默认是0.6&lt;/p&gt;

&lt;p&gt;如果Spark作业中，有较多的RDD持久化操作，该参数的值可以适当提高一些，保证持久化的数据能够容纳在内存中。避免内存不够缓存所有的数据，导致数据只能写入磁盘中，降低了性能。但是如果Spark作业中的shuffle类操作比较多，而持久化操作比较少，那么这个参数的值适当降低一些比较合适。此外，如果发现作业由于频繁的gc导致运行缓慢（通过spark web ui可以观察到作业的gc耗时），意味着task执行用户代码的内存不够用，那么同样建议调低这个参数的值。&lt;/p&gt;

&lt;h4 id=&quot;sparkshufflememoryfraction&quot;&gt;spark.shuffle.memoryFraction&lt;/h4&gt;
&lt;p&gt;该参数用于设置shuffle过程中一个task拉取到上个stage的task的输出后，进行聚合操作时能够使用的Executor内存的比例，默认是0.2。也就是说，Executor默认只有20%的内存用来进行该操作。shuffle操作在进行聚合时，如果发现使用的内存超出了这个20%的限制，那么多余的数据就会溢写到磁盘文件中去，此时就会极大地降低性能。&lt;/p&gt;

&lt;h4 id=&quot;示例&quot;&gt;示例&lt;/h4&gt;
&lt;p&gt;./bin/spark-submit &lt;br /&gt;
  –master yarn-cluster &lt;br /&gt;
  –num-executors 100 &lt;br /&gt;
  –executor-memory 6G &lt;br /&gt;
  –executor-cores 4 &lt;br /&gt;
  –driver-memory 1G &lt;br /&gt;
  –conf spark.default.parallelism=1000 &lt;br /&gt;
  –conf spark.storage.memoryFraction=0.5 &lt;br /&gt;
  –conf spark.shuffle.memoryFraction=0.3 \&lt;/p&gt;</content><author><name>nice</name></author><category term="Engineer" /><summary type="html">Spark存储机制</summary></entry><entry><title type="html">Transformer后续</title><link href="https://bigbigda.github.io/2023/02/19/WorkAfterTransformer/" rel="alternate" type="text/html" title="Transformer后续" /><published>2023-02-19T00:00:00+08:00</published><updated>2023-02-19T00:00:00+08:00</updated><id>https://bigbigda.github.io/2023/02/19/WorkAfterTransformer</id><content type="html" xml:base="https://bigbigda.github.io/2023/02/19/WorkAfterTransformer/">&lt;p&gt;[toc]&lt;/p&gt;

&lt;h3 id=&quot;简介&quot;&gt;简介&lt;/h3&gt;

&lt;p&gt;在之前我们介绍了attention-is-all-you-need这篇文章，事实上自从2017年Transformer结构提出后，截止目前其已经席卷了DeepLearning各个应用方向，不管是Bert还是GPT，还是之前介绍的视觉、多模态等工作，其主干网络都离不开Transformer结构。&lt;/p&gt;

&lt;p&gt;本文主要是想介绍Bert和GPT之外，其他一些采用Transformer结构的重要工作。比如RoBERTa、BART、T5等&lt;/p&gt;

&lt;h4 id=&quot;典型工作一句话总结&quot;&gt;典型工作一句话总结&lt;/h4&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;工作&lt;/th&gt;
      &lt;th&gt;介绍&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;RoBERTa&lt;/td&gt;
      &lt;td&gt;充分挖掘BERT模型结构优点，仅通过调整训练目标策略和训练数据集就大幅提升了模型效果&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;DEBEARTa&lt;/td&gt;
      &lt;td&gt;主体为encoder结构，SOTA，广泛应用与kaggle比赛&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;BART&lt;/td&gt;
      &lt;td&gt;encoder-decoder结构&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;T5&lt;/td&gt;
      &lt;td&gt;encoder-decoder结构，相对位置编码，多个生成任务的SOTA模型&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;分类&quot;&gt;分类&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Pretraining Architecture&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Encoder Pretraining&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Decoder Pretraining&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Transformer (Encoder-Decoder) Pretraining&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Pretraining Task
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Language Modeling (LM):&lt;/strong&gt;Predict next token (in the case of unidirectional LM) or previous and next token&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Masked Language Modeling (MLM):&lt;/strong&gt; mask out some tokens from the input sentences and then trains the model to predict the masked tokens by the rest of the tokens&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Permuted Language Modeling (PLM):&lt;/strong&gt; same as LM but on a random permutation of input sequences. A permutation is randomly sampled from all possible permutations. Then some of the tokens are chosen as the target, and the model is trained to predict these targets.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Denoising Autoencoder (DAE):&lt;/strong&gt; take a partially corrupted input (e.g. Randomly sampling tokens from the input and replacing them with [MASK] elements. randomly deleting tokens from the input, or shuffling sentences in random order) and aim to recover the original undistorted input.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Contrastive Learning (CTL):&lt;/strong&gt; A score function for text pairs is learned by assuming some observed pairs of text that are more semantically similar than randomly sampled text.
        &lt;h4 id=&quot;主要相关模型&quot;&gt;主要相关模型&lt;/h4&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;http://pic.inoodles.online/imgimage-20230219224946848.png&quot; alt=&quot;image-20230219224946848&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;主要相关模型y轴表示参数量&quot;&gt;主要相关模型（y轴表示参数量）&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;http://pic.inoodles.online/imgimage-20230219225226575.png&quot; alt=&quot;image-20230219225226575&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;roberta&quot;&gt;RoBERTa&lt;/h3&gt;

&lt;p&gt;RoBERTa: A Robustly Optimized BERT Pretraining Approach&lt;/p&gt;

&lt;h4 id=&quot;背景&quot;&gt;背景&lt;/h4&gt;

&lt;p&gt;本文发表于2019年，作者发现BERT被低估了，他们指出通过超参的调节、训练数据补充、训练目标的微调，原始BERT的效果可以得到明显的提升，超过当时所有BERT改进工作（例如XLNet）&lt;/p&gt;

&lt;h4 id=&quot;优化点&quot;&gt;优化点&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;增大训练时间、增加batchSize大小、更多训练数据
    &lt;ul&gt;
      &lt;li&gt;原始BERT使用BOOKCORPUS和English WIKIPEDIA，总共16G未压缩文本&lt;/li&gt;
      &lt;li&gt;本文使用了五个训练文本，数据总量达160G&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;移除next-sentence预测任务
    &lt;ul&gt;
      &lt;li&gt;原始BERT包括两个预训练任务：MLM（预测被mask的词）、NSP（预测输入中第二部分是不是第一部分的下一句）&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;使用更长的训练序列&lt;/li&gt;
  &lt;li&gt;使用动态的mask&lt;/li&gt;
  &lt;li&gt;输入文本编码
    &lt;ul&gt;
      &lt;li&gt;使用GPT中提出的BPE
        &lt;ul&gt;
          &lt;li&gt;BPE是一种sub-character的编码方式，最早用于压缩，主要做法是对所有训练文本中出现频率最高的子串（例如”app”)进行编码，最终未编码的用字母直接表示&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;deberta&quot;&gt;DeBERTa&lt;/h3&gt;

&lt;p&gt;DEBERTA: DECODING-ENHANCED BERT WITH DISENTANGLED ATTENTION&lt;/p&gt;

&lt;h4 id=&quot;简介-1&quot;&gt;简介&lt;/h4&gt;

&lt;p&gt;本文在BERT和RoBERTa的基础上进行改进提出了DeBERTa模型，共有15亿参数。基于此模型的大量下游实验都取得了优于RoBERTa的效果。尤其是在SuperGLUE上取得了优于人类的效果。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;disentangled attention mechanism：使用相对位置的位置编码层，attention计算也基于这两部分分别进行&lt;/li&gt;
  &lt;li&gt;enhanced mask decoder: 在最终softmax之前考虑绝对位置&lt;/li&gt;
  &lt;li&gt;利用一个对抗式训练方法来增强模型泛化性&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;模型训练&quot;&gt;模型训练&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;训练DeBERTa large 模型（L=12, H=768, A=12）使用6台DGX-2（合计96个V100 GPU），batchSize=2k，训练20天&lt;/li&gt;
  &lt;li&gt;混合多个数据源后去重，实际使用约78G&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;实验结果&quot;&gt;实验结果&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;http://pic.inoodles.online/imgimage-20230225005644789.png&quot; alt=&quot;image-20230225005644789&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;debertav3&quot;&gt;DeBERTaV3&lt;/h3&gt;

&lt;h4 id=&quot;简介-2&quot;&gt;简介&lt;/h4&gt;

&lt;p&gt;相比DeBERTa，主要提出了两个训练方法优化，效果明显提升，成为了NLU任务新SOTA&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;借鉴ELECTRA，引入类似GAN的训练方法（即将原模型结构作为Generator，新增一个Discriminator）&lt;/li&gt;
  &lt;li&gt;发现上述结构中的embedding-share虽然有用，但是生成器和判别器优化目标不同会导致难以训练。提出GDES，本质是判别器不再更新embedding&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;bart&quot;&gt;BART&lt;/h3&gt;

&lt;p&gt;BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension&lt;/p&gt;

&lt;p&gt;Facebook&lt;/p&gt;

&lt;h4 id=&quot;简介-3&quot;&gt;简介&lt;/h4&gt;

&lt;p&gt;BART是一个使用sequence-to-sequence结构的denoising autoencoder。&lt;/p&gt;

&lt;p&gt;其预训练任务为恢复一段被加噪的文本。作者尝试了许多增加噪音的方法，发现最有效的方法是将输入随机shuffle以及in-filling（将输入中任意长度、包括0长度的片段用&lt;strong&gt;一个&lt;/strong&gt;掩码代替）&lt;/p&gt;

&lt;p&gt;在NLU任务（GLUE和SQuAD）上与RoBERTa效果类似，在NLG任务（abstractive、question answering、summarization、translation）取得当时SOTA效果。&lt;/p&gt;

&lt;p&gt;BART也提出了一个新的机器翻译任务方案：在BART encoder输入端接入一些transformer层，这些层负责将原文本转化为带目标的噪音文本，然后利用BART将这个文本去噪。&lt;/p&gt;

&lt;h4 id=&quot;模型结构&quot;&gt;模型结构&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;基于标准Transformer结构改造&lt;/li&gt;
  &lt;li&gt;ReLU激活函数修改为GeLUs&lt;/li&gt;
  &lt;li&gt;decoder每一个层新增了对encoder最后一个隐含层的cross-attention（原始Transformer也是这么处理的）&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;预训练&quot;&gt;预训练&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;预训练任务为恢复corrupted文本，loss为decoder输出和原始文本的交叉熵&lt;/li&gt;
  &lt;li&gt;Text Infilling：将输入中$\lambda$长度的文本替换为一个[mask]，$\lambda$取自泊松分布，为0时相当于在原文中直接插入一个[mask]&lt;/li&gt;
  &lt;li&gt;针对翻译任务时，首先将BART原结构中encoder的embedding层改为一个随机初始化的encoder，然后进行端到端训练。训练分两步，第一步固定BART大部分参数，主要更新随机初始化encoder、positional embedding，第二步训练全部参数，两步训练均基于BART最终输出对应的交叉熵loss。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;实验结果-1&quot;&gt;实验结果&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;http://pic.inoodles.online/imgimage-20230221013500803.png&quot; alt=&quot;image-20230221013500803&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;t5&quot;&gt;T5&lt;/h3&gt;

&lt;p&gt;Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer&lt;/p&gt;

&lt;p&gt;google，原文67页&lt;/p&gt;

&lt;p&gt;作者将所有任务都转化为text-to-text格式，例如英语翻译到德语的输入转化为 “translate English to German：sentence”，一个分类任务输入转为”mnli premise: sentence”。注意这里的前缀本质是一个超参，作者发现修改前缀的文本对最终效果影响不大&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://pic.inoodles.online/imgimage-20230222004524747.png&quot; alt=&quot;image-20230222004524747&quot; style=&quot;zoom: 33%;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;模型结构-1&quot;&gt;模型结构&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;基于原始Transformer&lt;/li&gt;
  &lt;li&gt;移除Layer Norm的bias；&lt;/li&gt;
  &lt;li&gt;残差连接之后做LayerNorm；&lt;/li&gt;
  &lt;li&gt;position encoding（不同频率的正余弦函数）变为相对位置编码，attention函数计算时，Q和V相乘计算attention数值时加入相对位置的编码，编码是可训练的embedding。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;c4数据集&quot;&gt;C4数据集&lt;/h4&gt;

&lt;p&gt;作者选取了Common Crawl数据集，该数据集每月自动从web上爬取20TB左右的数据，该数据集可能包含各种英语、代码以及内容重复，本文对这些数据做了进一步清理，最终大小约750G&lt;/p&gt;

&lt;h4 id=&quot;实验&quot;&gt;实验&lt;/h4&gt;

&lt;p&gt;本文的实验非常非常多，下图所示为其中4组&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;预训练任务方面，类似BERT的masked language modeling最好&lt;/li&gt;
  &lt;li&gt;Mask策略中，replace spans最好&lt;/li&gt;
  &lt;li&gt;mask率为15%时最佳&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/Users/mtdp/Library/Application Support/typora-user-images/image-20230224003929772.png&quot; alt=&quot;image-20230224003929772&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;评估任务&quot;&gt;评估任务&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;文本分类：GLUE &amp;amp; SuperGLUE，是测试通用语言理解能力的文本分类任务的集合，包括句子可接受性判断、情绪分析、释义/句子相似度、自然语言推断、指代消解、完成句子、词义消歧和问题回答。
    &lt;ul&gt;
      &lt;li&gt;GLUE进一步介绍：https://zhuanlan.zhihu.com/p/135283598&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;机器翻译：WMT English to German, French, and Romanian translation&lt;/li&gt;
  &lt;li&gt;文本摘要：CNN/Daily Mail abstractive summarization&lt;/li&gt;
  &lt;li&gt;智能问答：SQuAD question answering&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;参考资料&quot;&gt;参考资料&lt;/h3&gt;

&lt;p&gt;https://amatriain.net/blog/transformer-models-an-introduction-and-catalog-2d1e9039f376/ （介绍基于Transformer的50多篇相关工作）&lt;/p&gt;

&lt;p&gt;https://docs.google.com/spreadsheets/d/1ltyrAB6BL29cOv2fSpNQnnq2vbX8UrHl47d7FkIf6t4/edit#gid=0 （上文中整理的相关工作code链接及简介）&lt;/p&gt;</content><author><name>nice</name></author><category term="NLP" /><summary type="html">[toc]</summary></entry><entry><title type="html">Tools</title><link href="https://bigbigda.github.io/2023/02/17/Tools/" rel="alternate" type="text/html" title="Tools" /><published>2023-02-17T00:00:00+08:00</published><updated>2023-02-17T00:00:00+08:00</updated><id>https://bigbigda.github.io/2023/02/17/Tools</id><content type="html" xml:base="https://bigbigda.github.io/2023/02/17/Tools/">&lt;h3 id=&quot;工具&quot;&gt;工具&lt;/h3&gt;

&lt;p&gt;reddit MachineLearning版&lt;/p&gt;

&lt;p&gt;hacker news&lt;/p&gt;

&lt;p&gt;paper with code （查sota）&lt;/p&gt;

&lt;p&gt;Hugging Face&lt;/p&gt;

&lt;h3 id=&quot;博客&quot;&gt;博客&lt;/h3&gt;

&lt;p&gt;https://www.jianshu.com/u/720c6853ff98 （简书上一个推荐系统系列）&lt;/p&gt;

&lt;h3 id=&quot;论文&quot;&gt;论文&lt;/h3&gt;

&lt;p&gt;https://dl.acm.org/doi/10.1145/2339530.2339654 （Position-normalized click prediction in search advertising）&lt;/p&gt;</content><author><name>nice</name></author><category term="Tools" /><summary type="html">工具</summary></entry><entry><title type="html">GPT系列</title><link href="https://bigbigda.github.io/2023/02/16/GPT/" rel="alternate" type="text/html" title="GPT系列" /><published>2023-02-16T00:00:00+08:00</published><updated>2023-02-16T00:00:00+08:00</updated><id>https://bigbigda.github.io/2023/02/16/GPT</id><content type="html" xml:base="https://bigbigda.github.io/2023/02/16/GPT/">&lt;h2 id=&quot;gpt系列&quot;&gt;GPT系列&lt;/h2&gt;

&lt;p&gt;[toc]&lt;/p&gt;

&lt;h3 id=&quot;相关论文及时间线&quot;&gt;相关论文及时间线&lt;/h3&gt;

&lt;p&gt;OpenAI&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;版本&lt;/th&gt;
      &lt;th&gt;论文名&lt;/th&gt;
      &lt;th&gt;时间&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;GPT&lt;/td&gt;
      &lt;td&gt;Improving Language Understanding by Generative Pre-Training&lt;/td&gt;
      &lt;td&gt;2018&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;GPT-2&lt;/td&gt;
      &lt;td&gt;Language Models are Unsupervised Multitask Learners&lt;/td&gt;
      &lt;td&gt;2019&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;GPT-3&lt;/td&gt;
      &lt;td&gt;Language Models are Few-Shot Learners 2020&lt;/td&gt;
      &lt;td&gt;2020&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;img src=&quot;http://pic.inoodles.online/imgimage-20230216005551634.png&quot; alt=&quot;image-20230216005551634&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;gpt10&quot;&gt;GPT1.0&lt;/h3&gt;

&lt;h4 id=&quot;简介&quot;&gt;简介&lt;/h4&gt;

&lt;p&gt;GPT1的提出在Transformer之后，而在Bert之前。作者想解决的主要问题是：自然语言处理领域现有模型主要基于“昂贵的”标记文本进行训练，而没有充分利用大量未标记文本。此外作者希望形成一个NLP领域新范式，即基于无标记文本预训练一个&lt;strong&gt;通用&lt;/strong&gt;模型，下游任务仅采用少量标记数据在前者基础上进行微调。&lt;/p&gt;

&lt;h4 id=&quot;模型&quot;&gt;模型&lt;/h4&gt;

&lt;h5 id=&quot;无监督预训练&quot;&gt;无监督预训练&lt;/h5&gt;

&lt;p&gt;&lt;img src=&quot;http://pic.inoodles.online/imgimage-20230216012322859.png&quot; alt=&quot;image-20230216012322859&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;有监督微调&quot;&gt;有监督微调&lt;/h5&gt;

&lt;p&gt;Loss = Loss1+Loss2；其中Loss1为预训练的Loss函数，即用来学习下一个单次，Loss2为微调数据Label本身对应的损失函数&lt;/p&gt;

&lt;h5 id=&quot;针对特定任务的输入转化&quot;&gt;针对特定任务的输入转化&lt;/h5&gt;

&lt;p&gt;对于文本分类任务，我们只需要直接讲语句输入模型即可；这里主要指的是针对输入是两个句子（例如相似度计算）或多个句子（文本选择）的情况如何使用此模型，其实方法与BERT类似，将多个句子拼接起来，中间新增一个分隔符&lt;/p&gt;

&lt;h4 id=&quot;实验效果&quot;&gt;实验效果&lt;/h4&gt;

&lt;h3 id=&quot;gpt-20&quot;&gt;GPT 2.0&lt;/h3&gt;

&lt;h4 id=&quot;文中meta-learning指的什么&quot;&gt;文中meta-learning指的什么&lt;/h4&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;作者指出，对于单个NLP任务，我们可以把模型看作$P(output&lt;/td&gt;
      &lt;td&gt;input)$ ，但对于多个任务，模型本质上是$P(output&lt;/td&gt;
      &lt;td&gt;input,task)$，进一步，作者指出对于NLP任务，我们可以通过在input（一段文本）前缀任务类型来将将两个condition（input和task）统一。具体的，一个翻译任务训练样本可以看作 (translate to french, english text, french text)，一个阅读理解任务训练样本可以看作 (answer the question, document, question, answer)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&quot;输入表示-bpe&quot;&gt;输入表示-BPE&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;之前论文表明，byte-level表示的语言模型比word-level表示的要差，作者也验证了这一点&lt;/li&gt;
  &lt;li&gt;Byte Pair Encoding（BPE）介于两者中间&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;模型结构&quot;&gt;模型结构&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;主要沿用OpenAI GPT model，一小部分改动&lt;/li&gt;
  &lt;li&gt;Layer normalization被移动到每一个block的开头&lt;/li&gt;
  &lt;li&gt;最后一个self-attention块后新增一个layer normalization&lt;/li&gt;
  &lt;li&gt;初始化中考虑了残差结构数量的影响&lt;/li&gt;
  &lt;li&gt;词典数量增加到50257，context大小从512增加到1024 （context大小是什么？）&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;实验&quot;&gt;实验&lt;/h4&gt;

&lt;h5 id=&quot;模型规模&quot;&gt;模型规模&lt;/h5&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;参数数量&lt;/th&gt;
      &lt;th&gt;层数&lt;/th&gt;
      &lt;th&gt;d_model&lt;/th&gt;
      &lt;th&gt;备注&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;117M&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;768&lt;/td&gt;
      &lt;td&gt;与GPT参数量相同&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;345M&lt;/td&gt;
      &lt;td&gt;24&lt;/td&gt;
      &lt;td&gt;1024&lt;/td&gt;
      &lt;td&gt;与BERT参数量相同&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;762M&lt;/td&gt;
      &lt;td&gt;36&lt;/td&gt;
      &lt;td&gt;1280&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1542M&lt;/td&gt;
      &lt;td&gt;48&lt;/td&gt;
      &lt;td&gt;1600&lt;/td&gt;
      &lt;td&gt;GPT-2&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;gpt-3&quot;&gt;GPT-3&lt;/h3&gt;

&lt;h4 id=&quot;简介-1&quot;&gt;简介&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;GPT-3参数规模175 billion （1750亿）&lt;/li&gt;
  &lt;li&gt;in-context learning&lt;strong&gt;（应该文本技术上最主要创新）&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;之前视觉任务也会提one-shot、few-shot，但是这都是指只用很少数据去fine-tune；而GPT-3提出的是完全不进行fine-tune，也即in-context learning，那如果不进行fine-tune如何利用这些监督样本呢，方法是把这些样本构造成测试任务输入的一部分（输入示例：“进行英文翻译中文，例如one对应一，two对应二，那three对应？”）&lt;/li&gt;
      &lt;li&gt;这个方法有点像prompt的扩展&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;模型结构-1&quot;&gt;模型结构&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;类似GPT2，但在Transformer层使用了”alternating dense and locally banded sparse attention patterns”（具体是啥不知道）&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;其他&quot;&gt;其他&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;in-context learning没有办法给太多例子（比如好几百），因为输入长度不能过长&lt;/li&gt;
  &lt;li&gt;作者在训练更大版本模型时使用更大batch-size，一个是为了加快训练，另一个&lt;strong&gt;反直觉&lt;/strong&gt;原因是发现模型越大，反而越不容易过拟合&lt;/li&gt;
  &lt;li&gt;基于gpt-3的一些好玩应用：https://platform.openai.com/examples&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;附录&quot;&gt;附录&lt;/h3&gt;

&lt;h4 id=&quot;gpt和bert的比较&quot;&gt;GPT和BERT的比较&lt;/h4&gt;

&lt;p&gt;如前所述，GPT相比BERT提出的更早，其与BERT也分别选择了Transformer的两个结构——decoder和encoder，除了模型结构上的差异，更根本的差异是GPT是一个采用前文预测下一个词的标准语言模型，而BERT是一个基于“完形填空”训练任务的带掩码语言模型（Masked Language Model）。参考李沐的观点，GPT的技术创新性更高，但同时任务训练难度也更大。从最终结果上看，标准版本BERT和GPT1.0规模大小相近，但效果更好，而BERT Large性能显著优于BERT，这也导致了BERT一文的影响力远高于GPT。&lt;/p&gt;

&lt;h4 id=&quot;花絮参考沐神观点&quot;&gt;花絮（参考沐神观点）&lt;/h4&gt;

&lt;p&gt;在GPT出来后，很快BERT就发表了，GPT采用的decoder架构，BERT采用的是encoder，从效果上来讲BERT取得了胜利，那对于GPT的作者而言，如果要继续做工作怎么办呢，假设也改成encoder路线，那无疑是承认之前的路线错了，这样一来之前工作的意义会更加大打折扣。但如果继续采用decoder，那就得通过增加训练数据集大小让效果比bert更好，但假如增加后还没有bert好或和bert差不多呢？方法就是换一个讲故事的思路，这也就是GPT-2以zero-shot为最大创新点去写整个文章的原因；相反，如果作者说我用了比BERT多5倍的参数量训了一个模型，各项指标比BERT好一点点，那这个文章的工程味就太重了，没什么意思。所以说做研究不能一条路走到黑。&lt;/p&gt;

&lt;p&gt;论文的价值=问题重要性x创新性x效果，GPT-2选择了增加创新性的指标，但因为最终效果一般，所以整个工作最后价值度没有很高；而到了GPT-3，作者又退回到GPT的设定，即few-shot learning，但重点是真的做出了炸裂的效果。&lt;/p&gt;</content><author><name>nice</name></author><category term="NLP" /><summary type="html">GPT系列</summary></entry><entry><title type="html">ViLT</title><link href="https://bigbigda.github.io/2023/02/14/ViLT/" rel="alternate" type="text/html" title="ViLT" /><published>2023-02-14T00:00:00+08:00</published><updated>2023-02-14T00:00:00+08:00</updated><id>https://bigbigda.github.io/2023/02/14/ViLT</id><content type="html" xml:base="https://bigbigda.github.io/2023/02/14/ViLT/">&lt;h2 id=&quot;vilt-vision-and-language-transformer-without-convolution-or-region-supervision&quot;&gt;ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision&lt;/h2&gt;

&lt;p&gt;ICML2021&lt;/p&gt;

&lt;h3 id=&quot;简介&quot;&gt;简介&lt;/h3&gt;

&lt;p&gt;图文多模态模型通常由三部分组成，即文本编码器（TE）、视觉编码器（VE）、模态融合（MI）。如下图所示，ViLT作者根据不同部分计算量的比较将多模态模型分为4类。本次分享选择b类型和d类型分别介绍一篇典型工作&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://pic.inoodles.online/imgimage-20230216004102047.png&quot; alt=&quot;image-20230216004102047&quot; /&gt;&lt;/p&gt;

&lt;p&gt;随着预训练-微调范式被用于视觉-文本联合任务中，业界出现了许多Vision-and-Language Pre-training（VLP）模型，VLP模型涉及对文本信息和视觉信息的处理，本文之前大部分工作依赖一个目标检测任务的CNN结构进行视觉特征提取，这种做法有两个缺陷：&lt;/p&gt;

&lt;p&gt;（1）计算速度非常慢：主要是因为视觉特征提取网络复杂度很高&lt;/p&gt;

&lt;p&gt;（2）表达能力受限：一方面不是端到端，另一方面目标检测任务本身分类数量有限&lt;/p&gt;

&lt;p&gt;本文主要贡献是：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;提出了一种非常简单的VLP模型架构（即前述分类中第四种），取得了巨大的执行速度和参数效率提升&lt;/li&gt;
  &lt;li&gt;将目标检测从多模态框架中移除，同时在图文任务取得可比结果（注: 最终效果距离当时SOTA仍有差距）&lt;/li&gt;
  &lt;li&gt;提出了一些有效的训练技巧（图像增强、全词掩码等）&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;模型结构&quot;&gt;模型结构&lt;/h3&gt;

&lt;h4 id=&quot;文本编码器&quot;&gt;文本编码器&lt;/h4&gt;

&lt;p&gt;预训练bert模型的tokenizer&lt;/p&gt;

&lt;h4 id=&quot;视觉编码器&quot;&gt;视觉编码器&lt;/h4&gt;

&lt;h6 id=&quot;基于region-feature的&quot;&gt;基于Region Feature的&lt;/h6&gt;

&lt;p&gt;之前绝大部分VLP模型采用这种方法，核心思路是借鉴Faster R-CNN的架构，通过一个region proposal network（RPN）来提出一系列区域，然后采用NMS等方法将候选减少到数百，再以此作为图像特征。&lt;/p&gt;

&lt;h6 id=&quot;基于grid-feature&quot;&gt;基于Grid Feature&lt;/h6&gt;

&lt;p&gt;类似Region Feature，通常采用ResNet等网络结构，一个优势是便于端到端fine-tune&lt;/p&gt;

&lt;h6 id=&quot;基于patch-projection的-本文采用&quot;&gt;基于Patch Projection的 （本文采用）&lt;/h6&gt;

&lt;p&gt;借鉴ViT论文，将图片分为32x32大小的patch，然后将每个patch通过一个线性层，最终将所有线性映射后结果拉直为一个序列&lt;/p&gt;

&lt;h4 id=&quot;模态融合及整体结构&quot;&gt;模态融合及整体结构&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;主题结构和Bert非常类似&lt;/li&gt;
  &lt;li&gt;文本和图片embedding前都有一个数字表达模态类型（灰色）&lt;/li&gt;
  &lt;li&gt;Loss函数
    &lt;ul&gt;
      &lt;li&gt;Image Text Matching（图文是否匹配，此外增加word Patch Alignment也用于计算匹配度）&lt;/li&gt;
      &lt;li&gt;Masked Language Modeling（预测masked text tokens）&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;http://pic.inoodles.online/imgimage-20230216004134316.png&quot; alt=&quot;image-20230216004134316&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;训练技巧&quot;&gt;训练技巧&lt;/h4&gt;

&lt;p&gt;针对具体场景，作者引入两个非常有效的训练技巧&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;全词掩码（Whole Word Masking）：因为许多原始token通过上下文很容易猜出，不利于学习与图片信息的交互，所以将整个单次完整掩盖&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;图片增强：之前多模态方法，尤其是c方法，训练时都是提前将原图转化为特征，数据增强就需要重新生成特征，所以一般没有进行；本文的方法十分适合，作者使用后也有明显效果提升。值得注意的是，为了避免数据增强后图文不一致，作者没有使用cut-off和color inversion这两种方法。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;实验结果&quot;&gt;实验结果&lt;/h3&gt;

&lt;h4 id=&quot;模型训练&quot;&gt;模型训练&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;64 NVIDIA V100 GPUs，3天&lt;/li&gt;
  &lt;li&gt;batchsize=4096&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;速度提升&quot;&gt;速度提升&lt;/h4&gt;

&lt;h4 id=&quot;visual-question-answering&quot;&gt;Visual Question Answering&lt;/h4&gt;

&lt;p&gt;VQAv2任务：给定一张图片和一个问题，最终从3129个回答中选择一个&lt;/p&gt;

&lt;p&gt;与其他VLP模型相比，ViLT表现不佳，作者觉得是因为任务集合经常询问是否含有某个目标之类的问题，借助目标检测的VLP框架天然的适合此场景。&lt;/p&gt;

&lt;h4 id=&quot;natural-language-for-visual-reasoning&quot;&gt;Natural Language for Visual Reasoning&lt;/h4&gt;

&lt;p&gt;NLVR2任务是一个二分类任务，给定两个图片和一个文本，从中选择一个图片。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://pic.inoodles.online/imgimage-20230216004204226.png&quot; alt=&quot;image-20230216004204226&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;讨论&quot;&gt;讨论&lt;/h3&gt;

&lt;p&gt;ViLT从最终效果来看相比SOTA模型还有差距，但是其最大的贡献是提出了将目标检测任务从多模态模型中移除出去的新框架。&lt;/p&gt;</content><author><name>nice</name></author><category term="MultiModal" /><summary type="html">ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision</summary></entry><entry><title type="html">淘宝详情页分发推荐算法总结</title><link href="https://bigbigda.github.io/2023/01/31/TaobaoDetailPageRecAlg/" rel="alternate" type="text/html" title="淘宝详情页分发推荐算法总结" /><published>2023-01-31T00:00:00+08:00</published><updated>2023-01-31T00:00:00+08:00</updated><id>https://bigbigda.github.io/2023/01/31/TaobaoDetailPageRecAlg</id><content type="html" xml:base="https://bigbigda.github.io/2023/01/31/TaobaoDetailPageRecAlg/">&lt;h3 id=&quot;春节后第一个post&quot;&gt;春节后第一个post&lt;/h3&gt;

&lt;p&gt;希望23年有更多的记录，更多的整理，更多的输出&lt;/p&gt;</content><author><name>nice</name></author><category term="Recsys" /><summary type="html">春节后第一个post</summary></entry></feed>